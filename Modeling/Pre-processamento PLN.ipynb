{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Pré-processamento ] Heurísticas computacionais para extração deconhecimento em problemas de maratona deprogramação - Parte 2 (PLN)\n",
    "\n",
    "Após realizar o tratamento básico dos dados, é necessário realizar alguns passos básicos de Processamento de Linguagem Natural (PLN) a fim de poder fornecer os problemas como entrada para algum classificador.\n",
    "\n",
    "### Importando as bibliotecas necessárias\n",
    "\n",
    "Antes de começar, é necessário importar algumas bibliotecas para tratar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarando constantes de trabalho\n",
    "\n",
    "Criação de \"variáveis de ambiente\" para auxiliar a obtenção de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langs? {PT, EN, ES}\n",
    "LANG_SLUG = \"EN\"\n",
    "PREPROCESSED_DATA_DIR = \"../Datasets/\"\n",
    "\n",
    "# Preprocessed files {%LANG_00_raw_data, %LANG_01_primary_data, %LANG_02_secondary_data, %LANG_03_terciary_data}.csv\n",
    "PREPROCESSED_FILE = \"%s%s%s\" % (PREPROCESSED_DATA_DIR, LANG_SLUG, \"_03_terciary_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "Aqui os textos de descrição, entrada e saída serão tokenizados (extraídos as palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[Read, 2, variables, ,, named, A, and, B, and,...</td>\n",
       "      <td>[The, input, file, will, contain, 2, integer, ...</td>\n",
       "      <td>[Print, the, letter, X, (, uppercase, ), with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[The, formula, to, calculate, the, area, of, a...</td>\n",
       "      <td>[The, input, contains, a, value, of, floating,...</td>\n",
       "      <td>[Present, the, message, ``, A=, '', followed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[Read, two, integer, values, ,, in, this, case...</td>\n",
       "      <td>[The, input, file, contains, 2, integer, numbe...</td>\n",
       "      <td>[Print, the, variable, SOMA, with, all, the, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[Read, two, integer, values, ., After, this, ,...</td>\n",
       "      <td>[The, input, file, contains, 2, integer, numbe...</td>\n",
       "      <td>[Print, PROD, according, to, the, following, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[Read, two, floating, points, ', values, of, d...</td>\n",
       "      <td>[The, input, file, contains, 2, floating, poin...</td>\n",
       "      <td>[Print, MEDIA, (, average, in, Portuguese, ), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem  \\\n",
       "1001  [Read, 2, variables, ,, named, A, and, B, and,...   \n",
       "1002  [The, formula, to, calculate, the, area, of, a...   \n",
       "1003  [Read, two, integer, values, ,, in, this, case...   \n",
       "1004  [Read, two, integer, values, ., After, this, ,...   \n",
       "1005  [Read, two, floating, points, ', values, of, d...   \n",
       "\n",
       "                                                     in  \\\n",
       "1001  [The, input, file, will, contain, 2, integer, ...   \n",
       "1002  [The, input, contains, a, value, of, floating,...   \n",
       "1003  [The, input, file, contains, 2, integer, numbe...   \n",
       "1004  [The, input, file, contains, 2, integer, numbe...   \n",
       "1005  [The, input, file, contains, 2, floating, poin...   \n",
       "\n",
       "                                                    out  \n",
       "1001  [Print, the, letter, X, (, uppercase, ), with,...  \n",
       "1002  [Present, the, message, ``, A=, '', followed, ...  \n",
       "1003  [Print, the, variable, SOMA, with, all, the, c...  \n",
       "1004  [Print, PROD, according, to, the, following, e...  \n",
       "1005  [Print, MEDIA, (, average, in, Portuguese, ), ...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lê o arquivo CSV e trata os objetos vazios\n",
    "rawDataDF = pd.read_csv(PREPROCESSED_FILE, sep=\";\", index_col = 0)\n",
    "rawDataDF.fillna(\"\", inplace = True)\n",
    "\n",
    "# Tokeniza os textos do problema\n",
    "tokenized = pd.DataFrame()\n",
    "tokenized[\"problem\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"description\"]), axis = 1)\n",
    "tokenized[\"in\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"input\"]), axis = 1)\n",
    "tokenized[\"out\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"output\"]), axis = 1)\n",
    "\n",
    "# Imprime parte do DF\n",
    "tokenized.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
