{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Pré-processamento ] Heurísticas computacionais para extração deconhecimento em problemas de maratona deprogramação - Parte 2 (PLN)\n",
    "\n",
    "Após realizar o tratamento básico dos dados, é necessário realizar alguns passos básicos de Processamento de Linguagem Natural (PLN) a fim de poder fornecer os problemas como entrada para algum classificador.\n",
    "\n",
    "### Importando as bibliotecas necessárias\n",
    "\n",
    "Antes de começar, é necessário importar algumas bibliotecas para tratar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import nltk\n",
    "import scipy\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarando constantes de trabalho\n",
    "\n",
    "Criação de \"variáveis de ambiente\" para auxiliar a obtenção de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langs? {PT, EN, ES}\n",
    "LANG_SLUG = \"EN\"\n",
    "GRAPHS_OUTPUT_DIR = \"../Graphs/\"\n",
    "PREPROCESSED_DATA_DIR = \"../Datasets/\"\n",
    "\n",
    "# Preprocessed files {%LANG_00_raw_data, %LANG_01_primary_data, %LANG_02_secondary_data, %LANG_03_terciary_data}.csv\n",
    "PREPROCESSED_FILE = \"%s%s%s\" % (PREPROCESSED_DATA_DIR, LANG_SLUG, \"_03_terciary_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "\n",
    "Aqui os textos de descrição, entrada e saída serão tokenizados (extraídos as palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[read, 2, variables, ,, named, a, and, b, and,...</td>\n",
       "      <td>[the, input, file, will, contain, 2, integer, ...</td>\n",
       "      <td>[print, the, letter, x, (, uppercase, ), with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[the, formula, to, calculate, the, area, of, a...</td>\n",
       "      <td>[the, input, contains, a, value, of, floating,...</td>\n",
       "      <td>[present, the, message, ``, a=, '', followed, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[read, two, integer, values, ,, in, this, case...</td>\n",
       "      <td>[the, input, file, contains, 2, integer, numbe...</td>\n",
       "      <td>[print, the, variable, soma, with, all, the, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[read, two, integer, values, ., after, this, ,...</td>\n",
       "      <td>[the, input, file, contains, 2, integer, numbe...</td>\n",
       "      <td>[print, prod, according, to, the, following, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[read, two, floating, points, ', values, of, d...</td>\n",
       "      <td>[the, input, file, contains, 2, floating, poin...</td>\n",
       "      <td>[print, media, (, average, in, portuguese, ), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem  \\\n",
       "1001  [read, 2, variables, ,, named, a, and, b, and,...   \n",
       "1002  [the, formula, to, calculate, the, area, of, a...   \n",
       "1003  [read, two, integer, values, ,, in, this, case...   \n",
       "1004  [read, two, integer, values, ., after, this, ,...   \n",
       "1005  [read, two, floating, points, ', values, of, d...   \n",
       "\n",
       "                                                     in  \\\n",
       "1001  [the, input, file, will, contain, 2, integer, ...   \n",
       "1002  [the, input, contains, a, value, of, floating,...   \n",
       "1003  [the, input, file, contains, 2, integer, numbe...   \n",
       "1004  [the, input, file, contains, 2, integer, numbe...   \n",
       "1005  [the, input, file, contains, 2, floating, poin...   \n",
       "\n",
       "                                                    out  \n",
       "1001  [print, the, letter, x, (, uppercase, ), with,...  \n",
       "1002  [present, the, message, ``, a=, '', followed, ...  \n",
       "1003  [print, the, variable, soma, with, all, the, c...  \n",
       "1004  [print, prod, according, to, the, following, e...  \n",
       "1005  [print, media, (, average, in, portuguese, ), ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lê o arquivo CSV e trata os objetos vazios\n",
    "rawDataDF = pd.read_csv(PREPROCESSED_FILE, sep=\";\", index_col = 0)\n",
    "rawDataDF.fillna(\"\", inplace = True)\n",
    "\n",
    "# Tokeniza os textos do problema\n",
    "tokenized = pd.DataFrame()\n",
    "tokenized[\"problem\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"description\"]), axis = 1)\n",
    "tokenized[\"in\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"input\"]), axis = 1)\n",
    "tokenized[\"out\"] = rawDataDF.apply(lambda x : nltk.word_tokenize(x[\"output\"]), axis = 1)\n",
    "\n",
    "# Converte todas as letras para \"minúsculas\"\n",
    "tokenized[\"problem\"] = tokenized.apply(lambda x: [w.lower() for w in x[\"problem\"]], axis = 1)\n",
    "tokenized[\"in\"] = tokenized.apply(lambda x: [w.lower() for w in x[\"in\"]], axis = 1)\n",
    "tokenized[\"out\"] = tokenized.apply(lambda x: [w.lower() for w in x[\"out\"]], axis = 1)\n",
    "\n",
    "# Imprime parte do DF\n",
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção de stopwords\n",
    "\n",
    "Remoção de stopwords e limpeza de caracteres (remoção de palavras não alfanuméricas) com o auxílio do NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[read, variables, named, b, make, sum, two, va...</td>\n",
       "      <td>[input, file, contain, integer, numbers]</td>\n",
       "      <td>[print, letter, x, uppercase, blank, space, eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[formula, calculate, area, circumference, defi...</td>\n",
       "      <td>[input, contains, value, floating, point, doub...</td>\n",
       "      <td>[present, message, followed, value, variable, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[read, two, integer, values, case, variables, ...</td>\n",
       "      <td>[input, file, contains, integer, numbers]</td>\n",
       "      <td>[print, variable, soma, capital, letters, blan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[read, two, integer, values, calculate, produc...</td>\n",
       "      <td>[input, file, contains, integer, numbers]</td>\n",
       "      <td>[print, prod, according, following, example, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[read, two, floating, points, values, double, ...</td>\n",
       "      <td>[input, file, contains, floating, points, valu...</td>\n",
       "      <td>[print, media, average, portuguese, according,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem  \\\n",
       "1001  [read, variables, named, b, make, sum, two, va...   \n",
       "1002  [formula, calculate, area, circumference, defi...   \n",
       "1003  [read, two, integer, values, case, variables, ...   \n",
       "1004  [read, two, integer, values, calculate, produc...   \n",
       "1005  [read, two, floating, points, values, double, ...   \n",
       "\n",
       "                                                     in  \\\n",
       "1001           [input, file, contain, integer, numbers]   \n",
       "1002  [input, contains, value, floating, point, doub...   \n",
       "1003          [input, file, contains, integer, numbers]   \n",
       "1004          [input, file, contains, integer, numbers]   \n",
       "1005  [input, file, contains, floating, points, valu...   \n",
       "\n",
       "                                                    out  \n",
       "1001  [print, letter, x, uppercase, blank, space, eq...  \n",
       "1002  [present, message, followed, value, variable, ...  \n",
       "1003  [print, variable, soma, capital, letters, blan...  \n",
       "1004  [print, prod, according, following, example, b...  \n",
       "1005  [print, media, average, portuguese, according,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "\n",
    "tokenized[\"problem\"] = tokenized.apply(lambda x: [w for w in x[\"problem\"] if (w not in stoplist and w.isalpha())], axis = 1)\n",
    "tokenized[\"in\"] = tokenized.apply(lambda x: [w for w in x[\"in\"] if (w not in stoplist and w.isalpha())], axis = 1)\n",
    "tokenized[\"out\"] = tokenized.apply(lambda x: [w for w in x[\"out\"] if (w not in stoplist and w.isalpha())], axis = 1)\n",
    "\n",
    "# Imprime parte do DF\n",
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de tag - Part Of Speech (POS)\n",
    "\n",
    "Aplicação de POS tags utilizando a NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[(read, JJ), (variables, NNS), (named, VBN), (...</td>\n",
       "      <td>[(input, NN), (file, NN), (contain, NN), (inte...</td>\n",
       "      <td>[(print, NN), (letter, NN), (x, NNP), (upperca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[(formula, NN), (calculate, NN), (area, NN), (...</td>\n",
       "      <td>[(input, NN), (contains, VBZ), (value, NN), (f...</td>\n",
       "      <td>[(present, JJ), (message, NN), (followed, VBD)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[(read, VB), (two, CD), (integer, JJR), (value...</td>\n",
       "      <td>[(input, NN), (file, NN), (contains, VBZ), (in...</td>\n",
       "      <td>[(print, NN), (variable, JJ), (soma, NN), (cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[(read, VB), (two, CD), (integer, JJR), (value...</td>\n",
       "      <td>[(input, NN), (file, NN), (contains, VBZ), (in...</td>\n",
       "      <td>[(print, NN), (prod, NN), (according, VBG), (f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[(read, VB), (two, CD), (floating, VBG), (poin...</td>\n",
       "      <td>[(input, NN), (file, NN), (contains, VBZ), (fl...</td>\n",
       "      <td>[(print, NN), (media, NNS), (average, JJ), (po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem  \\\n",
       "1001  [(read, JJ), (variables, NNS), (named, VBN), (...   \n",
       "1002  [(formula, NN), (calculate, NN), (area, NN), (...   \n",
       "1003  [(read, VB), (two, CD), (integer, JJR), (value...   \n",
       "1004  [(read, VB), (two, CD), (integer, JJR), (value...   \n",
       "1005  [(read, VB), (two, CD), (floating, VBG), (poin...   \n",
       "\n",
       "                                                     in  \\\n",
       "1001  [(input, NN), (file, NN), (contain, NN), (inte...   \n",
       "1002  [(input, NN), (contains, VBZ), (value, NN), (f...   \n",
       "1003  [(input, NN), (file, NN), (contains, VBZ), (in...   \n",
       "1004  [(input, NN), (file, NN), (contains, VBZ), (in...   \n",
       "1005  [(input, NN), (file, NN), (contains, VBZ), (fl...   \n",
       "\n",
       "                                                    out  \n",
       "1001  [(print, NN), (letter, NN), (x, NNP), (upperca...  \n",
       "1002  [(present, JJ), (message, NN), (followed, VBD)...  \n",
       "1003  [(print, NN), (variable, JJ), (soma, NN), (cap...  \n",
       "1004  [(print, NN), (prod, NN), (according, VBG), (f...  \n",
       "1005  [(print, NN), (media, NNS), (average, JJ), (po...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o POS_TAG\n",
    "tagged = pd.DataFrame()\n",
    "tagged[\"problem\"] = tokenized.apply(lambda x: nltk.pos_tag(x[\"problem\"]), axis = 1)\n",
    "tagged[\"in\"] = tokenized.apply(lambda x: nltk.pos_tag(x[\"in\"]), axis = 1)\n",
    "tagged[\"out\"] = tokenized.apply(lambda x: nltk.pos_tag(x[\"out\"]), axis = 1)\n",
    "\n",
    "# Imprime parte do DF\n",
    "tagged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Lemmatizador\n",
    "\n",
    "Conversão das palavras para suas formas inflexionadas utilizando o WordNetLemmatizer. **Ex.:** \"following\" -> \"follow\".\n",
    "\n",
    "Caso o idioma escolhido seja o português, deve-se utilizar algum lemmatizador alternativo ou então o próprio stemmer para a língua portuguesa disponível na NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[(read, JJ), (variable, NNS), (name, VBN), (b,...</td>\n",
       "      <td>[(input, NN), (file, NN), (contain, NN), (inte...</td>\n",
       "      <td>[(print, NN), (letter, NN), (x, NNP), (upperca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[(formula, NN), (calculate, NN), (area, NN), (...</td>\n",
       "      <td>[(input, NN), (contain, VBZ), (value, NN), (fl...</td>\n",
       "      <td>[(present, JJ), (message, NN), (follow, VBD), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[(read, VB), (two, CD), (integer, JJR), (value...</td>\n",
       "      <td>[(input, NN), (file, NN), (contain, VBZ), (int...</td>\n",
       "      <td>[(print, NN), (variable, JJ), (soma, NN), (cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[(read, VB), (two, CD), (integer, JJR), (value...</td>\n",
       "      <td>[(input, NN), (file, NN), (contain, VBZ), (int...</td>\n",
       "      <td>[(print, NN), (prod, NN), (accord, VBG), (foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>[(read, VB), (two, CD), (float, VBG), (point, ...</td>\n",
       "      <td>[(input, NN), (file, NN), (contain, VBZ), (flo...</td>\n",
       "      <td>[(print, NN), (medium, NNS), (average, JJ), (p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                problem  \\\n",
       "1001  [(read, JJ), (variable, NNS), (name, VBN), (b,...   \n",
       "1002  [(formula, NN), (calculate, NN), (area, NN), (...   \n",
       "1003  [(read, VB), (two, CD), (integer, JJR), (value...   \n",
       "1004  [(read, VB), (two, CD), (integer, JJR), (value...   \n",
       "1005  [(read, VB), (two, CD), (float, VBG), (point, ...   \n",
       "\n",
       "                                                     in  \\\n",
       "1001  [(input, NN), (file, NN), (contain, NN), (inte...   \n",
       "1002  [(input, NN), (contain, VBZ), (value, NN), (fl...   \n",
       "1003  [(input, NN), (file, NN), (contain, VBZ), (int...   \n",
       "1004  [(input, NN), (file, NN), (contain, VBZ), (int...   \n",
       "1005  [(input, NN), (file, NN), (contain, VBZ), (flo...   \n",
       "\n",
       "                                                    out  \n",
       "1001  [(print, NN), (letter, NN), (x, NNP), (upperca...  \n",
       "1002  [(present, JJ), (message, NN), (follow, VBD), ...  \n",
       "1003  [(print, NN), (variable, JJ), (soma, NN), (cap...  \n",
       "1004  [(print, NN), (prod, NN), (accord, VBG), (foll...  \n",
       "1005  [(print, NN), (medium, NNS), (average, JJ), (p...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert POS to WordNet POS\n",
    "# From https://www.machinelearningplus.com/nlp/lemmatization-examples-python/#wordnetlemmatizer\n",
    "def to_wn_pos(tagged_word):\n",
    "    tag_dict = {\"J\" : nltk.corpus.wordnet.ADJ,\n",
    "                \"N\" : nltk.corpus.wordnet.NOUN,\n",
    "                \"V\" : nltk.corpus.wordnet.VERB,\n",
    "                \"R\" : nltk.corpus.wordnet.ADV}\n",
    "    return tag_dict.get(tagged_word[1][0].upper(), nltk.wordnet.NOUN)\n",
    "\n",
    "# Aplica a lemmatização\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "lemmatized = pd.DataFrame()\n",
    "lemmatized[\"problem\"] = tagged.apply(lambda x: [(lemmatizer.lemmatize(tup[0], to_wn_pos(tup)), tup[1]) for tup in x[\"problem\"]], axis = 1)\n",
    "lemmatized[\"in\"] = tagged.apply(lambda x: [(lemmatizer.lemmatize(tup[0], to_wn_pos(tup)), tup[1]) for tup in x[\"in\"]], axis = 1)\n",
    "lemmatized[\"out\"] = tagged.apply(lambda x: [(lemmatizer.lemmatize(tup[0], to_wn_pos(tup)), tup[1]) for tup in x[\"out\"]], axis = 1)\n",
    "\n",
    "# Imprime parte do DF\n",
    "lemmatized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração da matriz termo-documento\n",
    "\n",
    "Como o objetivo deste trabalho é realizar a comparação entre a semântica dos problemas, então, torna-se mais viável tratar os problemas como sendo as linhas da matriz e as palavras (termos) como sendo as colunas (para possíveis fins de compactação posterior). **ATENÇÃO:** Por motivos de desempenho, as linhas da matriz termo-documento serão compostas pelo vocabulário e as colunas pelos problemas. Caso seja necessário, basta obter o DF transposto.\n",
    "\n",
    "#### Análise do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary dict shape :\n",
      "14252 4559 3931\n",
      "\n",
      "Problems (first ones):\n",
      "['tamanho', 'sunflower', 'renè', 'importância', 'rematched', 'flaw', 'rabbit', 'ação', 'consistency', 'surprised']\n",
      "\n",
      "Input (first ones):\n",
      "['tamanho', 'thus', 'vine', 'prix', 'topmost', 'rabbit', 'atk', 'ação', 'balloon', 'binding']\n",
      "\n",
      "Output (first ones):\n",
      "['tamanho', 'thus', 'sunflower', 'vine', 'mom', 'atk', 'balloon', 'minimize', 'th', 'carry']\n"
     ]
    }
   ],
   "source": [
    "# Vocabulário dos problemas, entrada e saída\n",
    "vocab = {\n",
    "    \"problem\" : set([]),\n",
    "    \"in\" : set([]),\n",
    "    \"out\" : set([])\n",
    "}\n",
    "\n",
    "lemmatized.apply(lambda x : vocab[\"problem\"].update(set([[] if a == [] else a[0] for a in x[\"problem\"]])), axis = 1)\n",
    "lemmatized.apply(lambda x : vocab[\"in\"].update(set([[] if a == [] else a[0] for a in x[\"in\"]])), axis = 1)\n",
    "lemmatized.apply(lambda x : vocab[\"out\"].update(set([[] if a == [] else a[0] for a in x[\"out\"]])), axis = 1)\n",
    "\n",
    "# Dimensões do dicionário de vocabulários\n",
    "print(\"Vocabulary dict shape :\")\n",
    "print(len(vocab[\"problem\"]), len(vocab[\"in\"]), len(vocab[\"out\"]))\n",
    "print(\"\\nProblems (first ones):\")\n",
    "print(list(vocab[\"problem\"])[:10])\n",
    "print(\"\\nInput (first ones):\")\n",
    "print(list(vocab[\"in\"])[:10])\n",
    "print(\"\\nOutput (first ones):\")\n",
    "print(list(vocab[\"out\"])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construção, efetiva, da matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Problems:  (14252, 1833)\n",
      "\n",
      "Input:  (4559, 1833)\n",
      "\n",
      "Output:  (3931, 1833)\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "      <th>...</th>\n",
       "      <th>2952</th>\n",
       "      <th>2953</th>\n",
       "      <th>2954</th>\n",
       "      <th>2955</th>\n",
       "      <th>2956</th>\n",
       "      <th>2957</th>\n",
       "      <th>2958</th>\n",
       "      <th>2959</th>\n",
       "      <th>2960</th>\n",
       "      <th>2961</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tamanho</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunflower</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renè</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>importância</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rematched</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1001  1002  1003  1004  1005  1006  1007  1008  1009  1010  ...  \\\n",
       "tamanho         0     0     0     0     0     0     0     0     0     0  ...   \n",
       "sunflower       0     0     0     0     0     0     0     0     0     0  ...   \n",
       "renè            0     0     0     0     0     0     0     0     0     0  ...   \n",
       "importância     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "rematched       0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "             2952  2953  2954  2955  2956  2957  2958  2959  2960  2961  \n",
       "tamanho         0     0     0     0     0     0     0     0     0     0  \n",
       "sunflower       0     0     0     0     0     0     0     0     0     0  \n",
       "renè            0     0     0     0     0     0     0     0     0     0  \n",
       "importância     0     0     0     0     0     0     0     0     0     0  \n",
       "rematched       0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 1833 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Procedimento definido para preencher a \"matriz\" termo-documento\n",
    "def parse_matrix_rows(row):\n",
    "    column = str(row.name)\n",
    "    problem_document_term_mat[column] = 0\n",
    "    in_document_term_mat[column] = 0\n",
    "    out_document_term_mat[column] = 0\n",
    "    \n",
    "    for tup in row[\"problem\"]:\n",
    "        problem_document_term_mat[column].loc[tup[0]] += 1\n",
    "    for tup in row[\"in\"]:\n",
    "        in_document_term_mat[column].loc[tup[0]] += 1\n",
    "    for tup in row[\"out\"]:\n",
    "        out_document_term_mat[column].loc[tup[0]] += 1\n",
    "    \n",
    "\n",
    "\n",
    "problem_document_term_mat = pd.DataFrame(index = vocab[\"problem\"])\n",
    "in_document_term_mat = pd.DataFrame(index = vocab[\"in\"])\n",
    "out_document_term_mat = pd.DataFrame(index = vocab[\"out\"])\n",
    "\n",
    "# Construção da \"matriz\" termo-documento (ou documento-termo)\n",
    "lemmatized.apply(parse_matrix_rows, axis = 1)\n",
    "\n",
    "# Imprime as dimensões das matrizes\n",
    "print(\"\\nProblems: \", problem_document_term_mat.shape)\n",
    "print(\"\\nInput: \", in_document_term_mat.shape)\n",
    "print(\"\\nOutput: \", out_document_term_mat.shape)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Imprime parte do df de problemas\n",
    "problem_document_term_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração do grafo de similaridade semântica\n",
    "\n",
    "Para a análise de similaridade entre textos, dever-se-á calcular a distância entre os vetores-coluna da matriz. Neste caso, será utilizada a distância do cosseno que, convenientemente, já é normalizada (a função cosseno só retorna valores entre -1 e 1, sendo que, como todos os vetores só posssuem valores positivos, ela retornará valores entre 0 e 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../Graphs\\\\Graph_1.gv.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula a distância do cosseno entre os problemas\n",
    "# Quanto mais próximo de 1 (pela função da biblioteca), mais distantes estão entre si\n",
    "\n",
    "problems_i = problem_document_term_mat.columns\n",
    "graph_path = \"%s%s\" % (GRAPHS_OUTPUT_DIR, \"Graph_1.gv\")\n",
    "graph = graphviz.Graph(name=\"Graph 1\", filename = graph_path, format = \"png\")\n",
    "added_vertex = []\n",
    "\n",
    "for index_n, problem_i in enumerate(problems_i):\n",
    "    for s_problem_i in problems_i[index_n + 1 : len(problems_i) - 1]:\n",
    "        dist = distance.cosine(problem_document_term_mat[problem_i].values, problem_document_term_mat[s_problem_i].values)\n",
    "        if dist < 0.3 :\n",
    "            if problem_i not in added_vertex:\n",
    "                graph.node(problem_i)\n",
    "                added_vertex.append(problem_i)\n",
    "            if s_problem_i not in added_vertex:\n",
    "                graph.node(s_problem_i)\n",
    "                added_vertex.append(s_problem_i)\n",
    "            graph.edge(problem_i, s_problem_i, label = str(dist))\n",
    "\n",
    "graph.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
